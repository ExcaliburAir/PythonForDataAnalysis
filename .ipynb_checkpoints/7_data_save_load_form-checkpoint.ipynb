{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读写文本格式的数据\n",
    "    # pandas中的解析函数\n",
    "'''\n",
    "read_csv 从文件，URL，文件型对象中加载带分隔符的数据。默认分隔符为逗号\n",
    "read_table 从文件，URL，文件型对象中加载带分隔符的数据。默认分隔符为制表符（“|t”）\n",
    "read_fwf 读取定宽列格式数据（也就是说，没有分隔符）\n",
    "read_clipboard 读取剪贴板中的数据，可以看作read_table的剪贴版。在将网页转换为表格时很有用\n",
    "\n",
    "'''\n",
    "\n",
    "# DataFrame时所用到一些技术\n",
    "'''\n",
    "索引： 将一个或多个列当作返回的DataFrame处理，以及是否从文件，用户获取列名。\n",
    "类型推断和数据转换：包括用户定义值的转换，缺失值标记列表等。\n",
    "日期解析：包括组合功能，比如将分散在多个列中的日期时间信息组合成结果中的单个列。\n",
    "迭代：支持对大文件进行逐块迭代。\n",
    "不规整数据问题：跳过一些行，页脚，注释或其他一些不重要的东西（比如由成千上万个逗号隔离开的数值数据）\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ch06/ex1.csv')\n",
    "\n",
    "# 没有列名的数据可以分配默认的列名，也可以自己定义列名\n",
    "pd.read_csv('ch06/ex2.csv', header=None)\n",
    "pd.read_csv('ch06/ex2.csv', names=['a', 'b', 'c', 'd', 'message'])\n",
    "\n",
    "# 也可以\n",
    "names = ['a', 'b', 'c', 'd', 'mesage']\n",
    "pd.read_csv('ch06/ex2.csv', names=names, index_col='message')\n",
    "\n",
    "parsed = pd.read_csv('ch06/csv_mindex.csv', index_col=['key1', 'key2'])\n",
    "result = pd.read_table('ch06/ex3.txt', sep='\\s+')\n",
    "pd.read_csv('ch06/ex4.csv', skiprows=[0, 2, 3])\n",
    "\n",
    "result = pd.read_csv('ch06/ex5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read_csv/read_table函数的参数\n",
    "'''\n",
    "path 表示文件系统位置，url，文件型对象的字符串\n",
    "sep或delimiter 用于对行中各字段进行拆分的字符序列或正则表达式\n",
    "header 用作列名的行好。默认为0，如果没有header行就应该设置为None\n",
    "index_col  用做列名的行好。默认为0第一行，如果没有header行就应该设置为None\n",
    "names 用于救国的列名列表，结合header=None\n",
    "skiprows 需要或略的行数从文件开始算，或需要跳过的行号列表\n",
    "na_values 一组用于替换NA的值\n",
    "comment 用于将注视信息从行尾拆分出去的字符（一个或多个）\n",
    "parse_dates 尝试将数据解析为日期，默认为False。如果为True，尝试解析所有列。此外，还可以指定需要解析的一组列号或列名。如果列表的元素为列表或元组，就会将多个列组合到一起再进行日期解析工作\n",
    "keep_data_col 如果链接多列解析日期，则保持参与链接的列。默认为False。\n",
    "converters 由列号/列名跟函数之间的映射关系组成的字典。\n",
    "dayfirst 当解析有歧义的日期时，将其看作国际格式。默认为False\n",
    "date_parser 用于解析日期的函数\n",
    "nrows 需要读取的行数\n",
    "iterator 返回一个TextParser以便逐块读取文件\n",
    "chunksize 文件块的大小（用于迭代）\n",
    "skip_footer 需要忽略的行数（从文件末尾出算起）\n",
    "verbose 打印各种解析器输出信息，比如“非数值列中缺失值的数量”等\n",
    "encoding 用于unicode的文本编码格式。例如，“utf-8”表示用UTF-8表示用UTF-8编码的文本\n",
    "squeeze 如果数据经解析后仅含一列，则返回Series\n",
    "thousands 千分位分隔符，如“，”或“.”\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 逐块读取文本文件\n",
    "    # 在处理大文件时，或找出大文件的参数集以便于后续处理时，你可能指向读取文件的一小部分或逐块对文件尽行迭代\n",
    "result = pd.read_csv('ch06/ex6.csv')\n",
    "pd.read_read_csv('ch06/ex6.csv', nrow=5)\n",
    "\n",
    "chunker = pd.read_csv('ch06/ex6.csv', chunksize=10000)\n",
    "tot = Series([])\n",
    "for piece in chunker:\n",
    "    tot = tot.add(piece['key'].value_counts(), fill_value=0)\n",
    "tot = tot.order(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将数据写出到文本格式\n",
    "data = pd.read_csv('ch06/ex5.csv')\n",
    "\n",
    "# 利用DataFrame的to_csv方法，我们可以将数据写到一个逗号分隔的文件中\n",
    "data.to_csv('ch06/out.csv')\n",
    "data.to_csv(sys.stdout, sep='|')\n",
    "\n",
    "data.to_csv(sys.stdout, index=False, header=False)\n",
    "\n",
    "# 写出一部分的列，并以你指定的书序排列\n",
    "data.to_csv(sys.stdout, index=False, cols=['a', 'b', 'c'])\n",
    "\n",
    "dates = pd.date_range('1/1/2000', periods=7)\n",
    "ts = Series(np.arange(7), index=dates)\n",
    "ts.to_csv('ch06/tseries.csv')\n",
    "\n",
    "Series.from_csv('ch06/tseries.csv', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 手工处理分隔符格式\n",
    "import csv\n",
    "f = open('ch06/ex7.csv')\n",
    "reader = csv.reader(f)\n",
    "\n",
    "for line in reader:\n",
    "    print line\n",
    "    \n",
    "lines = list(csv.reader(open('ch06/ex7.csv')))\n",
    "header, values = lines[0], lines[1:]\n",
    "data_dict = {h: v for h, v in zip(header, zip(*values))}\n",
    "data_dict\n",
    "\n",
    "class my_dialect(csv.Dialect):\n",
    "    lineterminator = '\\n'\n",
    "    delimiter = ';'\n",
    "    quotechar = '\"'\n",
    "    \n",
    "reader = csv.reader(f, diaect=my_dialect)\n",
    "\n",
    "# CSV语支选项\n",
    "'''\n",
    "delimiter 用于分隔字段的单子符字符串。默认为“，”\n",
    "lineterminator 用于写作操作的行结束符，默认为“\\r\\n”。读操作将忽略此选项，它能认出跨平台的行结束符\n",
    "quotechar 用于带有特殊字符（如分隔符）的字段的引用符号。默认为““”\n",
    "quoting 引用约定。可选值包括csv.QUOTE_ALL(引用所有字段)，csv,QUOTE_MINIMAL(只引用带有诸如分隔符之类特殊字符的字段)\n",
    "skipinitialspace 忽略分隔符后面的空白符。默认为False\n",
    "doublequote 如何处理字段内的引用符号。如果True，则双写。\n",
    "escapechar 用于对分隔符进行转义的字符串。\n",
    "'''\n",
    "\n",
    "with open('mydata.csv', 'w') as f:\n",
    "    writer = csv.writer(f, dialect=my_dialect)\n",
    "    writer.writerow(('one', 'two', 'three'))\n",
    "    writer.writerow(('1', '2', '3'))\n",
    "    writer.writerow(('4', '5', '6'))\n",
    "    writer.writerow(('7', '8', '9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# JSON数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XML和HTML：Web信息收集\n",
    "from lxml.html import parse\n",
    "from urllib2 import urlopen\n",
    "parsed = parse(urlopen('http://finance.yahoo.com/q/op?s=AAPL+Options'))\n",
    "doc = parsed.getroot()\n",
    "\n",
    "lnk = links[28]\n",
    "lnk.get('href')\n",
    "lnk.text_content()\n",
    "\n",
    "tables = doc.findall('.//table')\n",
    "calls = tables[9]\n",
    "puts = tables[13]\n",
    "rows = calls.findall('.//tr')\n",
    "\n",
    "def _unpack(row, kind='td'):\n",
    "    elts = row.findall('.//%s' % kind)\n",
    "    return [val.text_content() for val in elts]\n",
    "\n",
    "from pandas.io.parsers import TextParser\n",
    "def parse_options_data(table):\n",
    "    rows = table.findall('.//tr')\n",
    "    header = _unpack(rows[0], kind='th')\n",
    "    data = [_unpack(r) for r in rows[1:]]\n",
    "    return TexParser(data, names=header).get_chunk()\n",
    "\n",
    "call_data = parse_options_data(calls)\n",
    "put_data = parse_options_data(puts)\n",
    "call_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 利用lxml.objectify解析xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 二进制数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用HDF5格式\n",
    "store = pd.HDFStore('mydata.h5')\n",
    "store['obj1'] = frame\n",
    "store['obj1_col'] = frame['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取Microsoft Excel文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用HTML和Web API\n",
    "import requests\n",
    "url = 'http://search.twitter.com/search.json?q=python%2Opandas'\n",
    "resp = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用数据库\n",
    "import sqlite3\n",
    "\n",
    "query = \"\"\"\n",
    "CREATE TABLE test\n",
    "(a VARCHAR(20), b VARCHAR(20),\n",
    "c REAL, d INTEGER\n",
    ");\"\"\"\n",
    "\n",
    "con = sqlite3.connect(':memory:')\n",
    "con.execute(query)\n",
    "con.commit()\n",
    "\n",
    "data = [('Atlanta', 'Georgia', 1.25, 6),\n",
    "       ('Tallahassee', 'Florida', 2.6, 3),\n",
    "       ('Sacramento', 'California', 1.7, 5)]\n",
    "stmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\"\n",
    "con.executemany(stmt, data)\n",
    "con.commit()\n",
    "\n",
    "cursor.description\n",
    "DataFrame(rows, columns=zip(*cursor.description)[0])\n",
    "\n",
    "import pandas.io.sql as sql\n",
    "sql.read_frame('select * from test', con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 存取MongoDB中的数据\n",
    "import pymongo\n",
    "con = pymongo.Connection('localhost', port=27017)\n",
    "tweets = con.db.tweets\n",
    "\n",
    "import requests, json\n",
    "url = 'http...'\n",
    "data = json.loads(requests.get(url).text)\n",
    "cursor = tweets.find({'from_user': 'wesmckinn'})\n",
    "\n",
    "tweet_fields = ['created_at', 'from_user', 'id', 'text']\n",
    "result = DataFrame(list(cursor), columns=tweet_fields)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
